{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be095e14-9ce5-4b26-a449-02160f704bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29838806, 13),\n",
       "             ride_id  rideable_type              started_at  \\\n",
       " 0  63AF72AB3CD47753   classic_bike 2022-01-13 21:36:47.689   \n",
       " 1  9C0DAD8C1E0EA571   classic_bike 2022-01-16 17:56:23.889   \n",
       " 2  9576DDD8920974F5  electric_bike 2022-01-18 07:10:04.799   \n",
       " 3  962A466CC3AC6781   classic_bike 2022-01-22 12:10:10.225   \n",
       " 4  C2585407BA0FE3E9   classic_bike 2022-01-08 16:35:16.497   \n",
       " \n",
       "                  ended_at                start_station_name start_station_id  \\\n",
       " 0 2022-01-13 21:46:02.024                   5 Ave & E 63 St          6904.06   \n",
       " 1 2022-01-16 18:03:50.269  Grand Army Plaza & Plaza St West          4010.15   \n",
       " 2 2022-01-18 07:20:54.450                  W 20 St & 10 Ave          6306.01   \n",
       " 3 2022-01-22 12:20:06.899                   W 54 St & 9 Ave          6920.03   \n",
       " 4 2022-01-08 16:45:33.279              Sharon St & Olive St          5323.05   \n",
       " \n",
       "               end_station_name end_station_id  start_lat  start_lng  \\\n",
       " 0           Broadway & W 51 St        6779.04  40.766368 -73.971518   \n",
       " 1  Bedford Ave & Montgomery St        3736.03  40.672968 -73.970880   \n",
       " 2           Broadway & W 51 St        6779.04  40.745686 -74.005141   \n",
       " 3             10 Ave & W 28 St        6459.04  40.765849 -73.986905   \n",
       " 4      Driggs Ave & Lorimer St        5481.04  40.715353 -73.938560   \n",
       " \n",
       "      end_lat    end_lng member_casual  \n",
       " 0  40.762288 -73.983362        member  \n",
       " 1  40.665816 -73.956934        member  \n",
       " 2  40.762288 -73.983362        member  \n",
       " 3  40.750664 -74.001768        member  \n",
       " 4  40.721791 -73.950415        casual  ,\n",
       " ride_id               string[python]\n",
       " rideable_type               category\n",
       " started_at            datetime64[ns]\n",
       " ended_at              datetime64[ns]\n",
       " start_station_name    string[python]\n",
       " start_station_id      string[python]\n",
       " end_station_name      string[python]\n",
       " end_station_id        string[python]\n",
       " start_lat                    float64\n",
       " start_lng                    float64\n",
       " dtype: object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1 — imports\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import json  # stdlib, no install needed\n",
    "\n",
    "# Cell 2 — paths & file list (points at your 12 monthly ZIPs)\n",
    "data_dir = Path(\"/Users/renatabatista/Other Docs/Germany/CareerFoundry/Data Specialization/JupyterLab/citibike_2022/extracted/2022-citibike-tripdata\")\n",
    "zips = sorted(data_dir.glob(\"2022??-citibike-tripdata.zip\"))\n",
    "len(zips), zips[:3]  # quick check\n",
    "\n",
    "# Cell 3 — choose columns & dtypes to save memory (adjust if needed)\n",
    "usecols = [\n",
    "    \"ride_id\", \"rideable_type\", \"started_at\", \"ended_at\",\n",
    "    \"start_station_id\", \"start_station_name\",\n",
    "    \"end_station_id\", \"end_station_name\",\n",
    "    \"start_lat\", \"start_lng\", \"end_lat\", \"end_lng\",\n",
    "    \"member_casual\"\n",
    "]\n",
    "dtypes = {\n",
    "    \"ride_id\": \"string\",\n",
    "    \"rideable_type\": \"category\",\n",
    "    \"start_station_id\": \"string\",\n",
    "    \"start_station_name\": \"string\",\n",
    "    \"end_station_id\": \"string\",\n",
    "    \"end_station_name\": \"string\",\n",
    "    \"member_casual\": \"category\",\n",
    "    # lat/lng as float64 by default; leave them out of dtypes\n",
    "}\n",
    "parse_dates = [\"started_at\", \"ended_at\"]\n",
    "\n",
    "# Cell 4 — function that reads all CSVs inside one monthly ZIP\n",
    "def read_month_zip(zpath: Path) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    with ZipFile(zpath) as zf:\n",
    "        csv_names = [n for n in zf.namelist() if n.lower().endswith(\".csv\")]\n",
    "        for name in csv_names:\n",
    "            with zf.open(name) as f:\n",
    "                df = pd.read_csv(\n",
    "                    f,\n",
    "                    usecols=usecols,\n",
    "                    dtype=dtypes,\n",
    "                    parse_dates=parse_dates,\n",
    "                    low_memory=False\n",
    "                )\n",
    "                dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Cell 5 — read all months and vertically join (concatenate)\n",
    "monthly_frames = [read_month_zip(z) for z in zips]\n",
    "rides = pd.concat(monthly_frames, ignore_index=True)\n",
    "\n",
    "# quick sanity checks\n",
    "rides.shape, rides.head(), rides.dtypes.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324965ef-0f47-4073-9296-f4ed14cd4d54",
   "metadata": {},
   "source": [
    "## How the data-loading code works\n",
    "- I point data_dir at the folder containing the 12 monthly ZIP files for 2022 and glob them with the pattern 2022??-citibike-tripdata.zip.\n",
    "- To be memory-efficient, I define usecols (only the columns I need) and dtypes (categories/strings where appropriate) and parse the timestamp columns (started_at, ended_at) as dates.\n",
    "- For each month, I open the ZIP with zipfile.ZipFile and iterate over the CSV(s) inside. I read each CSV directly from the ZIP stream using pd.read_csv(zf.open(name), ...), avoiding temporary extraction to disk.\n",
    "- I collect the monthly DataFrames in a list and concatenate them into one big DataFrame rides using pd.concat(..., ignore_index=True).\n",
    "- Finally, I do a quick shape/head/dtypes check and (optionally) save the merged dataset to Parquet (recommended for size and speed) or a compressed CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37aade7c-1f62-4e6c-80fe-cafdf963c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick ONE of these:\n",
    "# Smaller & faster for future work\n",
    "rides.to_parquet(\"citibike_2022.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8aed9-3957-45d6-a1b6-baa7f0724880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0628e9-df61-43a2-80cf-7cf6315ff604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (citibike_2022)",
   "language": "python",
   "name": "citibike_2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
